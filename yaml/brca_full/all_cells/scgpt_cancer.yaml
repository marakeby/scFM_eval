run_id: 
dataset:
    module: data.scgpt_loader
    class: scgptLoader
    path: mnt/DATA/brca_full/cells_only_13gigs.h5ad #path is relative to DATA_PATH in setup_path.py
    load_raw: False
    label_key: cell_types
    batch_key: donor_id
    filter: 
      - column: timepoint
        values:
          - Pre
    layer_name: X  #if data exist in another layer (e.g. adta.layers['counts']). The data will be copied to adata.X
    train_test_split: data_splits/brca_full/brca_cell_type/train_test_split.json #path is relative to BASE_PATH in setup_path.py
    cv_splits: data_splits/brca_full/brca_cell_type/cv_splits.json #path is relative to BASE_PATH in setup_path.py

qc:
    # skip: True
    min_genes: 10
    min_cells: 10

preprocessing:
    # skip: True
    normalize: True
    target_sum: 10000
    apply_log1p: True

hvg:
    skip: True
    batch_key: batch
    n_top_genes: 4096
    flavor: seurat # expect logarithmized data
    
embedding:
    method: scgpt
    module: features.scgpt_extractor
    class: scGPT_Exractor
    viz: True
    eval: True
    params: 
        #Human
        model: scGPT_cancer
        model_dir: /home/jupyter/MODELS_old/scGPT
        batch_size: 8
        n_bins: 51
        max_seq_len: 2048

classification:
    skip: True
    module: models.classify
    class: ClassifierPipeline
    params:
        model: randomforest
        n_estimators: 100
        max_depth: 5
        cv: True
        label_map:
              treatment_naive: 0
              neoadjuvant_chemo: 1
    viz: True
    eval: True
