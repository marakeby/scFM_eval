run_id: 
dataset:
    module: data.scgpt_loader
    class: scgptLoader
    path: mnt/DATA/luad_brca/luad/luad_analysis2.h5ad #path is relative to DATA_PATH in setup_path.py
    load_raw: True
    label_key: group_id
    batch_key: sample_id
    layer_name: X  #if data exist in another layer (e.g. adta.layers['counts']). The data will be copied to adata.X
    train_test_split: data_splits/luad/luad2/train_test_split.json #path is relative to BASE_PATH in setup_path.py
    cv_splits: data_splits/luad/luad2/cv_splits.json #path is relative to BASE_PATH in setup_path.py

qc:
    # skip: True
    min_genes: 10
    min_cells: 10

preprocessing:
    # skip: True
    normalize: True
    target_sum: 10000
    apply_log1p: True

hvg:
    batch_key: batch
    n_top_genes: 4096
    flavor: seurat # expect logarithmized data
    
embedding:
    method: scgpt
    module: features.scgpt_extractor
    class: scGPT_Exractor
    viz: False
    eval: False
    params: 
        #Human
        model: scGPT_human
        model_dir: /home/jupyter/MODELS_old/scGPT
        batch_size: 8
        n_bins: 51
        max_seq_len: 4096

classification:
    module: models.classify
    class: ClassifierPipeline
    params:
        model: randomforest
        n_estimators: 100
        max_depth: 5
        cv: True
        train_funcs: 
            - avg
            - mil
            - vote
        label_map:
              treatment_naive: 0
              TKI: 1
    viz: True
    eval: True
